---
title: 'OpenAI'
description: 'Get started with OpenAI Realtime API'
icon: '/images/openai.svg'
---

<Check>
Find Elato on the [OpenAI Cookbook](https://cookbook.openai.com/examples/voice_solutions/running_realtime_api_speech_on_esp32_arduino_edge_runtime_elatoai) as a resource for Realtime Voice AI Hardware.
</Check>

<iframe
  className="w-full aspect-video rounded-xl"
  src="https://www.youtube.com/embed/o1eIAwVll5I"
  title="YouTube video player"
  frameBorder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>

OpenAI launched GPT-4o Realtime in 2024, which brought multimodal AI capabilities to the forefront. This model can understand and generate both text and audio in real-time, making it ideal for voice-based applications.

We are currently using the `gpt-realtime` series models for Elato's devices. More documentation here: https://platform.openai.com/docs/models/gpt-realtime.

To use OpenAI's models on your ESP32, simply set your `OPENAI_API_KEY` in the `.env` file in your Deno server (and NextJS web-app if you want to interact with a WebRTC client on screen). 

## Tutorial

<iframe
  className="w-full aspect-video rounded-xl"
  src="https://www.youtube.com/embed/bXrNRpGOJWw"
  title="YouTube video player"
  frameBorder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>
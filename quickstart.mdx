---
title: "Quickstart"
icon: "rocket"
description: "Start building awesome voice AI experiences in minutes ðŸš€"
---

import Discord from '/snippets/discord.mdx';

<iframe
  className="w-full aspect-video rounded-xl"
  src="https://www.youtube.com/embed/bXrNRpGOJWw"
  title="YouTube video player"
  frameBorder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>

### Step 1: Clone the repository

<AccordionGroup>
  <Accordion title="macOS / Linux">

```bash
git clone git@github.com:akdeb/ElatoAI.git
cd ElatoAI
```
  </Accordion>

  <Accordion title="Windows">

If you're on Windows, we recommend using **WSL2**.

1. Install WSL2 and Ubuntu.
2. Open **Ubuntu** (WSL).

```bash
git clone git@github.com:akdeb/ElatoAI.git
cd ElatoAI
```

  </Accordion>
</AccordionGroup>

### Step 2: Start Supabase (Local Backend)

We use Supabase (Postgres + Auth + Storage) to store users, devices, voices, personalities, and conversations.

Before you start:

- **Docker Desktop** must be installed and running.

<AccordionGroup>
  <Accordion title="macOS">

```bash
brew install supabase/tap/supabase
supabase start
```

  </Accordion>

  <Accordion title="Linux">

Install the Supabase CLI:

```bash
curl -fsSL https://supabase.com/install.sh | sh
```

Then start Supabase from the repo root:

```bash
supabase start
```

  </Accordion>

  <Accordion title="Windows">

Run everything inside **WSL2**, with Docker Desktop installed on Windows.

```bash
curl -fsSL https://supabase.com/install.sh | sh
supabase start
```

  </Accordion>
</AccordionGroup>

### Step 3: Set up your NextJS frontend

From the `frontend-nextjs` directory:

```bash
cd frontend-nextjs
npm install
cp .env.example .env.local
```

Then set the following in `.env.local`:

- `NEXT_PUBLIC_SUPABASE_ANON_KEY=<your-supabase-anon-key>`
- `OPENAI_API_KEY=<your-openai-api-key>`

Run the local NextJS setup:

```bash
npm run dev
```
<Callout icon="info" color="#FFC107">
To Login, use these credentials for local development:

- **Email**: `admin@elatoai.com`
- **Password**: `admin`

</Callout>

### Choose Edge Server option

<Tip>

1. **ELATO MODE (Free usage):** Got your own ESP32 DIY hardware device? 
   We offer a fully hosted server for free for up to 30 minutes per month. Register your device on the settings page and it will automatically connect to our edge server.
   - Sign up on [Elato](https://elatoai.com)
   - Register your device with your ESP32-S3's MAC Address in the [Settings page](https://elatoai.com/home/settings)
2. **DEV MODE (Local on your computer):** Alternatively, you can run your own edge server locally by following the instructions below and in the Deno server README.

**Pro Tip:** You can adjust your mode in `firmware-arduino/Config.h`.

</Tip>


### Step 4: If you run your own Deno edge server locally

The commands below are the same on macOS, Linux, and Windows (via WSL2). From the repo root:

```bash
cd server-deno
cp .env.example .env
```

Set your keys in `.env`:

- `SUPABASE_KEY=<your-supabase-anon-key>`
- `OPENAI_API_KEY=<your-openai-api-key>`
- `GEMINI_API_KEY=<your-gemini-api-key>`
- `XAI_API_KEY=<your-xai-api-key>`
- `ELEVENLABS_API_KEY=<your-elevenlabs-api-key>`
- `HUME_API_KEY=<your-hume-api-key>`

Run the server at port `8000`:

```bash
deno run -A --env-file=.env main.ts
```

### Step 5: Set up your firmware dev environment

<CardGroup>
 <Card
    title="PlatformIO (recommended)"
    icon="/images/pio.png"
    href="/platformio"
      horizontal
  >
  </Card>

   <Card
    title="Arduino IDE"
    icon="/images/arduino.png"
    href="/arduino"
      horizontal
  >
  </Card>
</CardGroup>


### Step 6: Setup complete!

<Accordion icon="rocket" title="Talk to your AI">
  1. Yay! You've now setup your NextJS frontend, Deno server and firmware succesfully.
  2. If your API Keys are set and have sufficient credits, you should now be able to talk to your voice AI characters.
</Accordion>

## Try these AI models

Elato now supports 5 major model providers. Now that you're fully set up, you can plug & play these within seconds.

<CardGroup cols={3}>

<Card title="Local AI" icon="laptop" disabled href="/local">
  Fully Local Home Toys are coming soon! ðŸ˜Š
</Card>

<Card title="OpenAI" icon="/images/openai.svg" href="/models/openai">
  Try out `gpt-realtime` multimodal models
</Card>

<Card title="Gemini" icon="/images/gemini.svg" href="/models/gemini">
  Try `Gemini Live API` models
</Card>

<Card title="Grok" icon="/images/grok.svg" href="/models/grok">
  You can try `Grok Voice Agents` on your hardware
</Card>

<Card title="Eleven Labs" icon="/images/eleven-labs.svg" href="/models/eleven-labs">
Bring your Eleven Labs Voice clones to your hardware
</Card>

<Card title="Hume AI" icon="/images/hume.svg" href="/models/hume">
Try Hume AI's expressive EVI-4 on your hardware
</Card>

</CardGroup>

<Discord />
